# HAPT

## Objective
Since there are many sensors are inbuilt in our smart phone to measure our position,
movements and orientation and because of these sensors the improvements in daily life of
human increases. Main objective of our project is to recognize the human’s activities by
analysing the mobile phone’s sensor data. More specifically, we have to make a model which
can predict or accurately classifies whether a person is performing the action of laying,
walking, walking upstairs, walking downstairs, sitting or standing only on the basis of mobile
phone sensor data. Using sensor data obtained from study participants performing six
different activities (walking, walking upstairs, walking downstairs, sitting, standing and
laying), our objective is to build a model that accurately classifies which of these activities is
being performed. This human activity recognition proposes many application and several
benefits. This mobile based health application can be beneficial for the elderly or senior
assistance. Also we can use this application for the personal health monitoring because
mobile will be attached with us and the application tracks our activity overtime. Our project
falls into the scope of Activity Recognition, a field that offers many benefits and enables
many new applications, for example step counters on your Smartphone, as well as
applications for elderly assistance and personal health monitoring.

##  Motivation and Overview
By understanding human action and their interaction with the surrounding is a key element
for the development of aforementioned intelligent system. Human activity recognition is field
that deals with the problems generates in the integration of sensing and reasoning, to provide
context- aware data that can confer the personalized support across an application. For
example, if we imagine a smart home which is equipped with various sensors and devices and
which is able to detect the working of all the appliances and presence of people in home. It is
possible to deduce the various activities performed by a person inside the home based on the
sensors signal with other relevant factors like time domain and date ( like a person in morning
is supposed to be in kitchen and coffee machine suggests that person is making breakfast).
That’s why the collected HAR can be absorbed to anticipate future people demands and can
be responsive for their purpose (example- automatic temperature set, automatic controlling of
light etc.). In the Human Activity Recognition system, still there are various issues which
need to be addressed like as battery limitation of wearable sensors, privacy concern regarding
continuous monitoring of activities, off-handedness of the wearable sensors, difficulty in
performing HAR (HUMAN ACTIVITY RECOGNITION) in real time and lack of fully
ambient systems able to reach users at any time.

### You can find the dataset on https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones

## GUI:
![alt text](https://github.com/HAPTDS/HAPT/blob/master/Images/GUI.png)


### To use this Follow the steps below:
1. Open the dataset link
2. Download it.
3. Read the descriptions.
4. Go to Train and Test data files.
5. Use try.py to put column names in the file.
6. See the .ipynb file in the Jupyter notebook.
7. Use dispaly.py to run the GUI and get full report of every algorithm used.
